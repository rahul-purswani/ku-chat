# KU-Chat: Finetuning Llama on custom data for QA tasks
## Overview
KU-Chat is a KU-focused question answering model built by fine-tuning Meta’s LLaMA-3.2-1B-Instruct using [LoRA (Low-Rank Adaptation)] and [PEFT]. It uses custom QAC pairs from KU’s website and supports both contextual and non-contextual inference.

## Inference Demo
https://github.com/user-attachments/assets/a30f6f76-4990-44a4-be7f-988a3f547d95

## BERT Scores

## ROUGE Scores
